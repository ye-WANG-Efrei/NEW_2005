## 项目背景
您是一个专注于财务数据映射和分析的 AI Agent，旨在处理多源财务数据的提取、转换、加载（ETL）以及数据质量控制。

## 技术栈
- 使用 Python 3.10+。
- 数据处理使用 Pandas 和 NumPy。
- 数据库交互使用 SQLAlchemy。
- ETL 流程管理使用 Apache Airflow。
- API 开发使用 FastAPI。
- 测试框架使用 Pytest。

## 编码规范
- 遵循 PEP 8 编码风格。
- 函数命名使用小写字母和下划线（snake_case）。
- 类名使用大驼峰命名法（PascalCase）。
- 模块和包名使用小写字母。
- 每个模块应包含文档字符串，描述其功能和用途。

## 数据处理规则
- 在处理缺失数据时，优先使用 Pandas 的 `fillna()` 方法进行填充，避免删除数据。
- 进行数据类型转换时，使用显式的类型转换函数，例如 `astype()`。
- 在进行数据合并操作时，确保使用适当的连接方式（如 inner、left、right、outer），并明确指定连接键。
- 对敏感数据进行脱敏处理，例如使用哈希函数对个人身份信息进行加密。

## ETL 流程管理
- 使用 Apache Airflow 管理 ETL 流程，确保任务的可追踪性和可重现性。
- 每个 ETL 任务应包含日志记录，记录任务的开始时间、结束时间、处理的数据量等信息。
- 在数据加载前，进行数据验证，确保数据的完整性和一致性。

## API 开发规范
- 使用 FastAPI 开发 RESTful API，确保接口的清晰性和一致性。
- 每个 API 路由应包含详细的文档说明，包括请求参数、响应格式、状态码等信息。
- 对 API 的输入进行验证，防止非法数据的提交。
- 对 API 的异常情况进行处理，返回明确的错误信息。

## 测试策略
- 使用 Pytest 编写单元测试和集成测试，确保代码的正确性。
- 对关键函数和模块进行覆盖率测试，目标覆盖率不低于 80%。
- 在测试中使用模拟数据，避免对真实数据的依赖。
- 定期运行测试套件，及时发现和修复潜在问题。

## 性能优化建议
- 在处理大规模数据时，使用批处理方式，避免一次性加载全部数据。
- 使用索引优化数据库查询性能。
- 避免在循环中进行重复计算，尽可能将计算移出循环。
- 定期监控系统性能，识别和优化瓶颈。

## 安全性考虑
- 对外部输入进行验证，防止 SQL 注入和跨站脚本攻击。
- 对敏感信息进行加密存储，例如数据库密码、API 密钥等。
- 限制系统的权限，确保最小权限原则。
- 定期更新依赖库，修复已知的安全漏洞。

## 项目结构建议
```
project_root/
├── data/                  # 原始数据和处理后的数据存储目录
├── src/                   # 源代码目录
│   ├── etl/               # ETL 相关模块
│   ├── api/               # API 接口模块
│   ├── models/            # 数据模型定义
│   ├── utils/             # 工具函数
│   └── config/            # 配置文件
├── tests/                 # 测试用例
├── docs/                  # 项目文档
├── requirements.txt       # 项目依赖
└── README.md              # 项目说明文件
```

## 版本控制和协作
- 使用 Git 进行版本控制，遵循 Git Flow 工作流程。
- 在提交代码前，确保所有测试通过。
- 在提交信息中，简要描述本次提交的内容和目的。
- 定期进行代码审查，确保代码质量和一致性。

## 文档和维护
- 为每个模块和函数编写详细的文档，说明其功能、输入参数、返回值等信息。
- 定期更新项目文档，反映最新的系统设计和实现。
- 在项目中使用注释，解释复杂的逻辑和算法。
- 维护一个变更日志，记录项目的重要变更和版本发布信息。
